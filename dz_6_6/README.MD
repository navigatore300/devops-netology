# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
---
_Ответ:_  
В первую очередь необходимо найти данную операцию, это можно сделать командой db.currentOp(). Например с указанием 
минимальной продолжительности запроса: db.currentOp({"secs_running": {$gte: 5}}). Выяснить id посмотрев в значении "opid".
После можно воспользоваться командой db.killOp() по id операции, указан в качестве параметра в скобках.
чтобы прервать выполнение команды. 
Чтобы ограничить время выполнения длительных запросов можно использование параметра maxTimeMS() для запросов CRUD в MongoDB.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
---
_Ответ:_  
В Redis есть два способа очистить просроченные записи: "ленивый" и "активный". 
В случае с ленивым - просроченные записи запрашиваются командой, активный способ - повторяется каждые 100 миллисекунд и 
проводит записи в состояние устаревшие, затем данные записи исключаются. ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP по умолчанию 
имеет значение 20, таким образом за раз можно пометить и очистить около 200 устаревших записей. Процесс проверки 
зациклится и мы ощутим задержки, а потом и вовсе не будут приниматься данные на запись, если появятся истекшие записи 
более 25% по отношению ко всем. В данном случае как раз так и получается. Такой подход необходим, чтобы не использовать 
слишком много памяти для ключей, срок действия которых уже истек.
 
## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

---
_Ответ:_  


Может быть запрос оперирует миллионами записей, либо в рамках одной записи используются слишком большие 
BLOB-поля. Необходимо уточнить, в чем проблема, можно попробовать включить slow_query_log.
Проанализировать проблемные запросы с помощью EXPLAIN. 
В документации MySQL ошибке посвящена [эта](https://dev.mysql.com/doc/refman/8.0/en/error-lost-connection.html) статья, 
в ней перечислены три возможные причины:
* Слишком объёмные запросы на миллионы строк, и рекомендуют увеличить параметр `net_read_timeout`
* Небольшое значение параметра `connect_timeout`, клиент не успевает установить соединение
* Размер сообщения/запроса превышает размер буфера, заданного в переменной ` max_allowed_packet` на сервере или опцией 
`--max_allowed_packet` клиента. 

Для решения проблемы необходимо изменить выше перечисленные параметры и локализовать проблему и желательно исправить 
причину ее возникновения (оптимизировать запросы, произвести инфраструктурные изменения).

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?
---
_Ответ:_  
Проблема в нехватке оперативной памяти. Мы видим, что система с помощью Out-Of-Memory Killer останавливает процесс, 
потребляющий слишком много оперативной памяти, чтобы защитить ядро от падения. В нашем случае останавливается процесс СУБД. 
Нужно либо добавить оперативки, либо ограничить использование оперативки для Postgres. По возможности необходимо 
оптимизировать проблемные запросы в БД, добавить недостающие индексы к таблицам.

Для настройки работы с оперативной памятью из Postgres можно регулировать следующие параметры:

**max_connections** - Определяет максимальное число одновременных подключений к серверу БД. По умолчанию 100 подключений. 
М ожно попробовать убавить его.

**shared_buffers** - Задаёт объём памяти, который будет использовать сервер баз данных для буферов в разделяемой памяти. 
По умолчанию установлено 128 мегабайт. На системах с RAM 1 Гб и выше рекомендуется использовать 25% от общего объема памяти. 
Если оперативки меньше, то нужно использовать меньший процент, чтобы оставить памяти для системы.

**wal_buffers** - Postgres сначала записывает записи в WAL (журнал предзаписи) в буферы, а затем эти буферы сбрасываются 
на диск. Размер буфера по умолчанию, равный -1, задаёт размер, равный 1/32 (около 3%) от shared_buffers, но не меньше 
чем 64 КБ и не больше чем размер одного сегмента WAL (обычно 16 МБ). Если у нас много одновременных подключений, то более 
высокое значение может повысить производительность. По документации рекомендуется использовать автонастройку со значением -1,
однако можно попробовать скорректировать этот параметр.

**effective_cache_size** - Определяет представление планировщика об эффективном размере дискового кеша, доступном для 
одного запроса. Это представление влияет на оценку стоимости использования индекса; чем выше это значение, тем больше 
вероятность, что будет применяться сканирование по индексу, чем ниже, тем более вероятно, что будет выбрано последовательное 
сканирование.  Значение по умолчанию — 4 гигабайта.

**temp_buffers** - Задаёт максимальный объём памяти, выделяемой для временных буферов в каждом сеансе. Эти существующие 
 только в рамках сеанса буферы используются исключительно для работы с временными таблицами. Значение по умолчанию — 8 
мегабайт. Сеанс выделяет временные буферы по мере необходимости до достижения предела, заданного параметром temp_buffers. 

**work_mem** - Задаёт базовый максимальный объём памяти, который будет использоваться во внутренних операциях при обработке 
запросов (например, для сортировки или хеш-таблиц), прежде чем будут задействованы временные файлы на диске. Значение по 
умолчанию — 4 мегабайта. Применяется для каждой операции сортировки или хеширования, при этом таких операций может быть 
несколько и одновременно в разных сеансах. Установка высокого значения может привести к высокому потреблению памяти.

**maintenance_work_mem** - это максимальный объём памяти для операций обслуживания БД, в частности VACUUM, CREATE INDEX 
и ALTER TABLE ADD FOREIGN KEY.  Значение по умолчанию — 64 мегабайта. Так как в один момент времени в сеансе может 
выполняться только одна такая операция и обычно они не запускаются параллельно, это значение вполне может быть гораздо 
больше work_mem. Увеличение этого значения может привести к ускорению операций очистки и восстановления БД из копии, но 
может приводить к высокому потреблению памяти при исполнении этих операций.